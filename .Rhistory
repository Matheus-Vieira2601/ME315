library(reticulate, lib.loc = "S:/R/R-4.3.2/library")
reticulate::repl_python()
library(reticulate)
py_discover_config()
library(reticulate)
py_discover_config()
use_python("C:/Program Files/Python312/python.exe")
reticulate::repl_python()
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(tidyxl))
cat("Iniciando Etapa 1: Conversão de XLSX para CSV...\n")
# --- Preparação dos arquivos ---
arquivo_zip <- here("Dados_P1_ME315.zip")
if (!file.exists(arquivo_zip)) { stop("Arquivo ZIP não encontrado.") }
diretorio_temporario <- tempdir()
nomes_xlsx_no_zip <- unzip(arquivo_zip, list = TRUE) %>%
filter(str_detect(Name, "\\.xlsx$")) %>%
pull(Name)
unzip(arquivo_zip, files = nomes_xlsx_no_zip, exdir = diretorio_temporario)
caminhos_xlsx <- file.path(diretorio_temporario, nomes_xlsx_no_zip)
# --- Carregamento de Pacotes ---
# Carrega todos os pacotes necessários para a execução completa da prova.
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(moments))  # Para cálculo de assimetria e curtose.
suppressPackageStartupMessages(library(jsonlite)) # Para salvar arquivos no formato JSON.
suppressPackageStartupMessages(library(knitr))    # Para criar tabelas formatadas em HTML.
cat("Iniciando Etapa 1.1: Conversão de XLSX para CSV...\n")
arquivo_zip <- here("Dados_P1_ME315.zip")
if (!file.exists(arquivo_zip)) { stop("Arquivo 'Dados_P1_ME315.zip' não encontrado.") }
diretorio_temporario <- tempdir()
nomes_xlsx_no_zip <- unzip(arquivo_zip, list = TRUE) %>%
filter(str_detect(Name, "\\.xlsx$")) %>%
pull(Name)
unzip(arquivo_zip, files = nomes_xlsx_no_zip, exdir = diretorio_temporario)
caminhos_xlsx <- file.path(diretorio_temporario, nomes_xlsx_no_zip)
caminhos_csv <- c()
for (caminho_excel in caminhos_xlsx) {
cat("  Convertendo:", basename(caminho_excel), "...\n")
df_excel <- read_excel(caminho_excel)
names(df_excel)[1] <- "Date" # Força o nome da primeira coluna.
novo_caminho_csv <- str_replace(caminho_excel, "\\.xlsx$", ".csv")
write_csv(df_excel, novo_caminho_csv)
caminhos_csv <- c(caminhos_csv, novo_caminho_csv)
}
cat("Etapa 1.1 Concluída: Arquivos convertidos para CSV.\n\n")
processa_chunk <- function(chunk, pos) {
chunk %>%
# A data no CSV é lida como texto, então convertemos para o formato Date.
mutate(Date = as.Date(as.character(Date), origin = "1899-12-30")) %>%
# Filtra o período de interesse, reduzindo a memória usada por cada chunk.
filter(Date >= ymd("2000-01-01") & Date <= ymd("2025-08-31"))
}
processa_chunk <- function(chunk, pos) {
chunk %>%
# A data no CSV é lida como texto, então convertemos para o formato Date.
mutate(Date = as.Date(as.character(Date), origin = "1899-12-30")) %>%
# Filtra o período de interesse, reduzindo a memória usada por cada chunk.
filter(Date >= ymd("2000-01-01") & Date <= ymd("2025-08-31"))
}
# Loop para ler cada arquivo CSV em chunks.
lista_de_dfs_processados <- list()
for (caminho_csv_atual in caminhos_csv) {
cat("  Lendo em chunks o arquivo:", basename(caminho_csv_atual), "...\n")
df_processado_do_arquivo <- read_csv_chunked(
caminho_csv_atual,
callback = DataFrameCallback$new(processa_chunk),
chunk_size = 100000 # Define o tamanho de cada chunk.
)
lista_de_dfs_processados <- append(lista_de_dfs_processados, list(df_processado_do_arquivo))
}
processa_chunk <- function(chunk, pos) {
chunk %>%
# **CORREÇÃO APLICADA AQUI**
# A data no CSV é lida como um texto (ex: "2000-01-01").
# Usamos as_date() do lubridate, que é a função correta e mais robusta
# para converter texto para o formato de data.
mutate(Date = as_date(Date)) %>%
filter(Date >= ymd("2000-01-01") & Date <= ymd("2025-08-31"))
}
lista_de_dfs_processados <- list()
for (caminho_csv_atual in caminhos_csv) {
cat("  Lendo em chunks o arquivo:", basename(caminho_csv_atual), "...\n")
df_processado_do_arquivo <- read_csv_chunked(
caminho_csv_atual,
callback = DataFrameCallback$new(processa_chunk),
chunk_size = 100000,
col_types = cols(.default = "c") # Lê tudo como texto para máxima compatibilidade.
)
lista_de_dfs_processados <- append(lista_de_dfs_processados, list(df_processado_do_arquivo))
}
precos_consolidados_df <- reduce(lista_de_dfs_processados, full_join, by = "Date")
cat("Etapa 1.2 Concluída: Todos os chunks foram lidos e consolidados.\n\n")
nomes_limpos <- str_extract(names(precos_consolidados_df), "[A-Z]{3,4}$")
nomes_limpos[1] <- "Date"
names(precos_consolidados_df) <- nomes_limpos
precos_filtrados_df <- precos_consolidados_df %>%
select(Date, where(~ (mean(is.na(.)) < 0.9))) %>%
filter(rowSums(is.na(select(., -Date))) < (ncol(.) - 1)) %>%
arrange(Date)
na_proportions <- map_dbl(precos_consolidados_df, ~mean(is.na(.)))
# 2. Identificamos os nomes das colunas que queremos manter (menos de 90% de NAs).
cols_to_keep <- names(na_proportions[na_proportions < 0.9])
# 3. Forçamos a manutenção da coluna 'Date', independentemente de NAs.
cols_to_keep <- union("Date", cols_to_keep)rdena por data, etapa crucial para a função lag().
na_proportions <- map_dbl(precos_consolidados_df, ~mean(is.na(.)))
# 2. Identificamos os nomes das colunas que queremos manter (menos de 90% de NAs).
cols_to_keep <- names(na_proportions[na_proportions < 0.9])
# 3. Forçamos a manutenção da coluna 'Date', independentemente de NAs.
cols_to_keep <- union("Date", cols_to_keep)
precos_filtrados_df <- precos_consolidados_df %>%
select(all_of(cols_to_keep)) %>% # 'all_of()' usa a lista de nomes que criamos.
filter(rowSums(is.na(select(., -Date))) < (ncol(.) - 1)) %>%
arrange(Date)
precos_consolidados_df <- precos_consolidados_df %>%
mutate(across(-Date, ~as.numeric(.)))
precos_consolidados_df <- precos_consolidados_df %>%
select(!where(~all(is.na(.)))) #
precos_consolidados_df <- precos_consolidados_df[, !is.na(names(precos_consolidados_df)) & names(precos_consolidados_df) != ""]
precos_consolidados_df <- precos_consolidados_df %>%
mutate(across(-Date, ~as.numeric(.)))
precos_consolidados_df <- precos_consolidados_df[, !is.na(names(precos_consolidados_df)) & names(precos_consolidados_df) != ""]
names(precos_consolidados_df)[1] <- "Date"
precos_consolidados_df <- precos_consolidados_df %>%
mutate(across(-Date, ~as.numeric(.)))
.
precos_consolidados_df <- precos_consolidados_df[, !is.na(names(precos_consolidados_df)) & names(precos_consolidados_df) != ""]
coluna_data <- precos_consolidados_df %>% select(Date)
names(precos_consolidados_df)[1] <- "Date"
precos_consolidados_df <- precos_consolidados_df[, !is.na(names(precos_consolidados_df)) & names(precos_consolidados_df) != ""]
precos_consolidados_df <- precos_consolidados_df %>%
mutate(across(-Date, ~as.numeric(.)))
# --- Carregamento de Pacotes ---
# Carrega o pacote tidyverse, um conjunto de pacotes para manipulação de dados.
suppressPackageStartupMessages(library(tidyverse))
# Carrega o pacote readxl, para ler arquivos do Excel (.xlsx).
suppressPackageStartupMessages(library(readxl))
# Carrega o pacote lubridate, para trabalhar com datas de forma mais fácil.
suppressPackageStartupMessages(library(lubridate))
# Carrega o pacote stringr, para manipulação de textos e strings.
suppressPackageStartupMessages(library(stringr))
# Carrega o pacote here, para encontrar arquivos no diretório do projeto.
suppressPackageStartupMessages(library(here))
# Carrega o pacote moments, para calcular assimetria (skewness) e curtose (kurtosis).
suppressPackageStartupMessages(library(moments))
# Carrega o pacote jsonlite, para salvar dados no formato JSON.
suppressPackageStartupMessages(library(jsonlite))
# Carrega o pacote knitr, para criar tabelas formatadas em relatórios.
suppressPackageStartupMessages(library(knitr))
install.packages("RSQLite")
library(RSQLite)
db = dbConnect(SQLite(),'disco.db')
db
dbListTables(db)
dbListFields(db,'albums')
album_db = dbGetQuery(db,'SELECT * FROM albums')
head(album_db)
dim(album_db)
sql = 'SELECT trackid, name FROM tracks ORDER BY name'
res = dbGetQuery(db, sql)
head(res)
sql = 'SELECT city FROM customers ORDER BY city'
ex3a = dbGetQuery(db, sql)
head(ex3a)
dim(ex3a)
sql = 'SELECT DISTINCT city FROM customers ORDER BY city'
ex3b = dbGetQuery(db, sql)
head(ex3b)
dim(ex3b)
dbGetQuery(db,'SELECT name, albumid FROM tracks WHERE albumid=1')
sql = paste('SELECT name, albumid, mediatypeid FROM tracks','WHERE mediatypeid IN (1, 2)','ORDER BY name LIMIT 5')
dbGetQuery(db, sql)
sql = paste('SELECT trackid, name, albumid FROM tracks',
'WHERE albumid IN',
'(SELECT albumid FROM albums WHERE artistid==12)',
'LIMIT 5')
dbGetQuery(db, sql)
sql = "SELECT trackid, name FROM tracks WHERE name GLOB '?ere*'"
dbGetQuery(db, sql)[1:5,]
sql = "SELECT trackid, name FROM tracks WHERE name GLOB '*[0-9]*'"
dbGetQuery(db, sql)[1:5,]
sql = 'SELECT albumid, COUNT(trackid) FROM tracks GROUP BY albumid'
dbGetQuery(db, sql)[1:5,]
sql = paste('SELECT albumid, COUNT(trackid)',
'FROM tracks GROUP BY albumid',
'HAVING albumid=1')
dbGetQuery(db, sql)
sql = paste('SELECT trackid, name, title FROM tracks',
'INNER JOIN albums ON albums.albumid=tracks.albumid')
dbGetQuery(db, sql)[1:5,]
sql = 'SELECT trackid, name, composer, unitprice FROM tracks ORDER BY unitprice'
res = dbGetQuery(db, sql)
head(res)
options(repos = c(CRAN = "[https://cran.rstudio.com/](https://cran.rstudio.com/)"))
# --- ETAPA 1: Preparação do Ambiente ---
# Verifica se o pacote 'reticulate' está instalado; se não, instala.
if (!requireNamespace("reticulate", quietly = TRUE)) {
install.packages("reticulate")
}
# Carrega o pacote que faz a ponte entre R e Python.
library(reticulate)
# Verifica se a biblioteca 'polars' do Python está instalada no ambiente do reticulate.
# Se não estiver, ele a instalará usando o pip.
tryCatch({
use_python(py_config()$python)
py_run_string("import polars")
cat("Polars já está instalado.\n")
}, error = function(e) {
cat("Polars não encontrado, instalando agora...\n")
py_install("polars")
})
py_install("polars")
tryCatch({
use_python(py_config()$python)
py_run_string("import polars")
cat("Polars já está instalado.\n")
}, error = function(e) {
cat("Polars não encontrado, instalando agora...\n")
py_install("polars")
})
reticulate::install_python()
# --- ETAPA 2: Execução do Código da Aula ---
# O comando `py_run_string()` permite executar um bloco de código Python diretamente.
# O bloco de código abaixo é o mesmo da aula, mas dentro de uma string do R.
py_run_string("
import polars as pl
import numpy as np
# --- Criação de DataFrames ---
df = pl.DataFrame(
{
'A': [1, 2, 3, 4, 5],
'frutas': ['banana', 'banana', 'maçã', 'maçã', 'banana'],
'B': [5, 4, 3, 2, 1],
'carnes': ['bovina', 'bovina', 'frango', 'frango', 'bovina'],
}
)
print('DataFrame inicial:')
print(df)
# --- Expressões e Contextos ---
df_selecionado = df.select(
pl.col('frutas'),
pl.col('carnes')
)
print('\\nDataFrame com colunas selecionadas:')
print(df_selecionado)
df_selecionado_str = df.select(
pl.col(pl.Utf8)
)
print('\\nDataFrame com colunas de string selecionadas:')
print(df_selecionado_str)
# --- Criando novas colunas com with_columns() ---
df_com_nova_coluna = df.with_columns(
(pl.col('B') + 5).alias('B_mais_5')
)
print('\\nDataFrame com uma nova coluna:')
print(df_com_nova_coluna)
df_com_novas_colunas = df.with_columns(
pl.sum('A', 'B').alias('A+B'),
(pl.col('A') - pl.col('B')).alias('A-B')
)
print('\\nDataFrame com múltiplas novas colunas:')
print(df_com_novas_colunas)
# --- Filtrando dados com filter() ---
df_filtrado = df.filter(
pl.col('A') > 2
)
print('\\nDataFrame filtrado (A > 2):')
print(df_filtrado)
df_filtrado_complexo = df.filter(
(pl.col('A') > 2) & (pl.col('frutas') == 'banana')
)
print('\\nDataFrame com filtro complexo (A > 2 E frutas == \\'banana\\'):')
print(df_filtrado_complexo)
# --- Agrupamentos com group_by() e agg() ---
df_agrupado = df.group_by('frutas').agg(
pl.sum('B').alias('soma_B_por_fruta'),
pl.mean('A').alias('media_A_por_fruta')
)
print('\\nDataFrame agrupado por \\'frutas\\':')
print(df_agrupado)
# --- Lazy API (Avaliação Preguiçosa) ---
lazy_df = df.lazy()
plano_de_execucao = (
lazy_df
.filter(pl.col('A') > 2)
.with_columns(
(pl.col('B') - pl.col('A')).alias('B-A')
)
)
print('\\nIsso é apenas o plano de execução, nenhum cálculo foi feito ainda:')
print(plano_de_execucao)
resultado_final = plano_de_execucao.collect()
print('\\nResultado final após executar .collect():')
print(resultado_final)
")
tryCatch({
use_python(py_config()$python)
py_run_string("import polars")
cat("Polars já está instalado.\n")
}, error = function(e) {
cat("Polars não encontrado, instalando agora...\n")
py_install("polars")
})
reticulate::repl_python()
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("../dados/")){
file.copy("../dados/disco.db"
,
"../dados/discoCopy.db")
}
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("../dados/")){
file.copy("../dados/disco.db","../dados/discoCopy.db")
}
if(!"discoCopy.db" %in% list.files("../dados/")){
file.copy("../dados/disco.db","../dados/discoCopy.db")
}
file.copy("../dados/disco.db","../dados/discoCopy.db")
file.copy("../dados/disco.db","../dados/discoCopy.db")
file.copy("../dados/disco.db","../dados/discoCopy.db")
file.copy("dados/disco.db","../dados/discoCopy.db")
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("../dados/")){
file.copy("../dados/disco.db","../dados/discoCopy.db")
}
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("../dados/")){
file.copy("../dados/disco.db","../dados/discoCopy.db")
}
db <- dbConnect(SQLite(),"../dados/discoCopy.db")
db <- dbConnect(SQLite(),"dados/discoCopy.db")
db <- dbConnect(SQLite(),"dados/discoCopy.db")
db <- dbConnect(SQLite(),"dados/discoCopy.db")
db <- dbConnect(SQLite(),"dados/discoCopy.db")
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("dados/")){
file.copy("dados/disco.db","../dados/discoCopy.db")
}
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("dados/")){
file.copy("dados/disco.db","dados/discoCopy.db")
}
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("dados/")){
file.copy("dados/disco.db","dados/discoCopy.db")
}
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("dados/")){
file.copy("dados/disco.db","dados/discoCopy.db")
}
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("dados/")){
file.copy("dados/disco.db","dados/discoCopy.db")
}
db <- dbConnect(SQLite(),"dados/discoCopy.db")
dbListTables(db)
db <- dbConnect(SQLite(),"dados/discoCopy.db")
dbListTables(db)
library(RSQLite)
library(tidyverse)
if(!"discoCopy.db" %in% list.files("dados/")){
file.copy("dados/disco.db","dados/discoCopy.db")
}
db <- dbConnect(SQLite(),"dados/discoCopy.db")
dbListTables(db)
reticulate::repl_python()
reticulate::repl_python()
